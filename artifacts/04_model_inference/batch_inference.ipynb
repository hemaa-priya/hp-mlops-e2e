{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a037d25-4285-4831-b832-2e42c7721a1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE CATALOG hp_az_catalog\")\n",
    "spark.sql(\"USE SCHEMA hp_iris_ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3615d84f-d90b-43ab-b334-7fab64925d96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow=='3.4.0'\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c009c550-0d5c-4c70-a8fe-1744e6d92b81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import mlflow\n",
    "from mlflow.pyfunc import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22e4ee23-024e-4f55-9ed2-02fc7da9fe10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load model from registry\n",
    "model_name = \"irisclassifierdemo\"\n",
    "model_uri = f\"models:/{model_name}@champion\"\n",
    "model = load_model(model_uri)\n",
    "\n",
    "# Load or simulate new data\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "print(X)\n",
    "# Predict\n",
    "preds = model.predict(X)\n",
    "pred_df = X.copy()\n",
    "pred_df[\"prediction\"] = preds\n",
    "pred_df[\"timestamp\"] = datetime.now()\n",
    "pred_df.columns = (\n",
    "    pred_df.columns\n",
    "    .str.replace(\" \", \"_\", regex=False)\n",
    "    .str.replace(\"(\", \"\", regex=False)\n",
    "    .str.replace(\")\", \"\", regex=False)\n",
    ")\n",
    "print(pred_df.head())\n",
    "df_spark = spark.createDataFrame(pred_df)\n",
    "df_spark.write.mode(\"append\").format(\"delta\").saveAsTable(\"iris_predictions\")\n",
    "print(\"Inference complete and saved to iris_predictions\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "batch_inference",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
